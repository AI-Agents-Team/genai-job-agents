{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75337298-902c-4c02-a63e-5f14f0641713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import logging\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87bd5648-b332-4887-9dee-e5b86283ca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from linkedin_api import Linkedin\n",
    "api = Linkedin(os.environ[\"LINKEDIN_EMAIL\"], os.environ[\"LINKEDIN_PASS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a2f2bae-b944-4395-8e54-75151b5f1968",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "def load_cv():\n",
    "    loader = PyPDFLoader(\"data/Touhidul Alam - Resume.pdf\")\n",
    "    pages = loader.load()\n",
    "    page_content = ''\n",
    "    for i in range(len(pages)):\n",
    "        page_content += pages[i].page_content\n",
    "    return page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dfe61c5-b2b6-4965-94c5-5bf65d3626b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_job_type(job_type):\n",
    "    job_type_mapping = {\n",
    "        \"full-time\": \"F\",\n",
    "        \"contract\": \"C\",\n",
    "        \"part-time\": \"P\",\n",
    "        \"temporary\": \"T\",\n",
    "        \"internship\": \"I\",\n",
    "        \"volunteer\": \"V\",\n",
    "        \"other\": \"O\"\n",
    "    }\n",
    "\n",
    "    return job_type_mapping.get(job_type.lower())\n",
    "\n",
    "def get_job_ids(keywords, location_name, job_type=None, limit=10, companies=None, industries=None, remote=None):\n",
    "    if job_type is not None:\n",
    "        job_type = get_job_type(job_type)\n",
    "    print(\"Arguments are:\", keywords, location_name, job_type, limit, companies, industries, remote)\n",
    "\n",
    "    job_postings = api.search_jobs(\n",
    "        keywords=keywords,\n",
    "        job_type=job_type,\n",
    "        location_name=location_name,\n",
    "        companies=companies,\n",
    "        industries=industries,\n",
    "        remote=remote,\n",
    "        limit = limit\n",
    "    )\n",
    "    # Extracting just the part after \"jobPosting:\" from the trackingUrn and the title using list comprehension\n",
    "    job_ids = [job['trackingUrn'].split('jobPosting:')[1] for job in job_postings]\n",
    "    return job_ids\n",
    "#job_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38f540b9-5e9c-4c76-9c6b-2316e6072b76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def get_job_details(job_id):\n",
    "    try:\n",
    "        job_data = api.get_job(job_id)  # Assuming this function is async and fetches job data\n",
    "        \n",
    "        # Construct the job data dictionary with defaults\n",
    "        job_data_dict = {\n",
    "            \"company_name\": job_data.get('companyDetails', {}).get('com.linkedin.voyager.deco.jobs.web.shared.WebCompactJobPostingCompany', {}).get('companyResolutionResult', {}).get('name', ''),\n",
    "            \"company_url\": job_data.get('companyDetails', {}).get('com.linkedin.voyager.deco.jobs.web.shared.WebCompactJobPostingCompany', {}).get('companyResolutionResult', {}).get('url', ''),\n",
    "            \"job_desc_text\": job_data.get('description', {}).get('text', ''),\n",
    "            \"work_remote_allowed\": job_data.get('workRemoteAllowed', ''),\n",
    "            \"job_title\": job_data.get('title', ''),\n",
    "            \"company_apply_url\": job_data.get('applyMethod', {}).get('com.linkedin.voyager.jobs.OffsiteApply', {}).get('companyApplyUrl', ''),\n",
    "            \"job_location\": job_data.get('formattedLocation', '')\n",
    "        }\n",
    "    except Exception as e:\n",
    "        # Handle exceptions or errors in fetching or parsing the job data\n",
    "        print(f\"Error fetching job details for job ID {job_id}: {str(e)}\")\n",
    "        job_data_dict = {\n",
    "            \"company_name\": '',\n",
    "            \"company_url\": '',\n",
    "            \"job_desc_text\": '',\n",
    "            \"work_remote_allowed\": '',\n",
    "            \"job_title\": '',\n",
    "            \"company_apply_url\": '',\n",
    "            \"job_location\": ''\n",
    "        }\n",
    "\n",
    "    return job_data_dict\n",
    "\n",
    "async def fetch_all_jobs(job_ids, batch_size=10):\n",
    "    results = []\n",
    "    for job_id in job_ids:\n",
    "        job_detail = await get_job_details(job_id)\n",
    "        results.append(job_detail)\n",
    "    return results\n",
    "\n",
    "async def job_threads(job_ids):\n",
    "    return await fetch_all_jobs(job_ids, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af21955b-ef74-44ff-a1a1-ee4d6c0fbfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define LLMs\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=\"gpt-4-0125-preview\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "#from langchain_groq import ChatGroq\n",
    "#llm = ChatGroq(temperature=0, groq_api_key=os.environ[\"GROQ_API_KEY\"], model_name=\"mixtral-8x7b-32768\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34562a63-b4d8-4d5b-a112-ee4e71763d97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 359 ms, sys: 35.7 ms, total: 395 ms\n",
      "Wall time: 434 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#define tools\n",
    "from langchain.agents import tool\n",
    "\n",
    "@tool\n",
    "def job_pipeline(keywords: str, location_name:str, job_type:str=None, limit:int=10, companies:str=None, industries:str=None, remote:str=None) -> dict:\n",
    "    \"\"\"Given a query identify job role, location and other optional arguments: job type, search/hit limit, companies, industries, remote job \n",
    "    and returns a list of Linkedin job posting title, company url, job location and detailed job description\"\"\"\n",
    "    job_ids = get_job_ids(keywords, location_name, job_type, limit, companies, industries, remote)\n",
    "    print(job_ids)\n",
    "    job_desc = asyncio.run(job_threads(job_ids))\n",
    "    return job_desc\n",
    "\n",
    "@tool\n",
    "def extract_cv() -> str:\n",
    "    \"\"\"From the CV text, extract relevant skill, experience, previous job responsibility, project experience etc.\n",
    "    Returns the unstructured CV text in a structured format later to analyzer. Consider only job relevant skill, not any personal information\"\"\"\n",
    "    text = load_cv()\n",
    "    return text\n",
    "\n",
    "@tool\n",
    "def generate_letter_for_specific_job() -> str:\n",
    "    \"\"\"Given the CV and highest relevant job, write a cover letter according to CV and matching with the job description. \\\n",
    "       Return the letter containing contact info, proper addresser, some description of the career and motivation for this job.\"\"\"\n",
    "    return text \n",
    "\n",
    "\n",
    "tools = [job_pipeline, extract_cv, generate_letter_for_specific_job]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a413a7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "def create_agent(llm: ChatOpenAI, tools: list, system_prompt: str):\n",
    "    # Each worker node will be given a name and some tools.\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                system_prompt,\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2fdc714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96163dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "members = [\"Searcher\", \"Analyzer\", \"Generator\"]\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following workers:  {members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status.\" \n",
    "    #\" Task will include, extracting cv content, searching jobs given user query, write modified cv according to best matched jobs.\"\n",
    "    \" When finished, respond with FINISH.\"\n",
    ")\n",
    "\n",
    "# Our team supervisor is an LLM node. It just picks the next agent to process\n",
    "# and decides when the work is completed\n",
    "options = [\"FINISH\"] + members\n",
    "# Using openai function calling can make output parsing easier for us\n",
    "function_def = {\n",
    "    \"name\": \"route\",\n",
    "    \"description\": \"Select the next role.\",\n",
    "    \"parameters\": {\n",
    "        \"title\": \"routeSchema\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"next\": {\n",
    "                \"title\": \"Next\",\n",
    "                \"anyOf\": [\n",
    "                    {\"enum\": options},\n",
    "                ],\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"next\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given the conversation above, who should act next?\"\n",
    "            \" Or should we FINISH? Select one of: {options}\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "supervisor_chain = (\n",
    "    prompt\n",
    "    | llm.bind_functions(functions=[function_def], function_call=\"route\") \n",
    "    | JsonOutputFunctionsParser() #OpenAIToolsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f070412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "import functools\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "\n",
    "# The agent state is the input to each node in the graph\n",
    "class AgentState(TypedDict):\n",
    "    # The annotation tells the graph that new messages will always\n",
    "    # be added to the current states\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    # The 'next' field indicates where to route to next\n",
    "    next: str\n",
    "\n",
    "\n",
    "search_agent = create_agent(llm, [job_pipeline], \"Given user queries of searching a role with necessary parameters, show the most relevant jobs with title, company url, job location and detailed job description\")\n",
    "search_node = functools.partial(agent_node, agent=search_agent, name=\"Searcher\")\n",
    "\n",
    "analyzer_agent = create_agent(llm, [extract_cv], \"Analyzer has access to the CV and most relevant jobs from the Searcher. Analyzer extract necessary information to be able to match with the jobs. Then analyze all the searched jobs and reason which one is highest matching.\")\n",
    "analyzer_node = functools.partial(agent_node, agent=analyzer_agent, name=\"Analyzer\")\n",
    "\n",
    "generator_agent = create_agent(llm, [generate_letter_for_specific_job], \"Given the extracted CV and highest matching job from the Analyzer, write a cover letter motivated with the job.\")\n",
    "generator_node = functools.partial(generator_agent, agent=generator_agent, name=\"Generator\")\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Searcher\", search_node)\n",
    "workflow.add_node(\"Analyzer\", analyzer_node)\n",
    "workflow.add_node(\"Generator\", generator_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f40f974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for member in members:\n",
    "    # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "# The supervisor populates the \"next\" field in the graph state\n",
    "# which routes to a node or finishes\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "# Finally, add entrypoint\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0198ca22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         +-----------+                                           \n",
      "                                         | __start__ |                                           \n",
      "                                         +-----------+                                           \n",
      "                                                *                                                \n",
      "                                                *                                                \n",
      "                                                *                                                \n",
      "                                        +------------+                                           \n",
      "                                      **| supervisor |****                                       \n",
      "                               *******  +------------+*   *******                                \n",
      "                        *******          ***           ***       *******                         \n",
      "                 *******                *                 ***           *******                  \n",
      "          *******                     **                     ***               *******           \n",
      "      ****              +----------------------+                **                    ****       \n",
      "      *                 | supervisor_condition |*                *                       *       \n",
      "      *                 +----------------------+ **********      *                       *       \n",
      "      *            *****            *           *****      **********                    *       \n",
      "      *       *****                 *                *****       *   **********          *       \n",
      "      *    ***                      *                     ***    *             *****     *       \n",
      "+----------+                  +---------+                 +-----------+            +----------+  \n",
      "| Analyzer |                  | __end__ |                 | Generator |            | Searcher |  \n",
      "+----------+                  +---------+                 +-----------+            +----------+  \n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "graph.get_graph().print_ascii()\n",
    "#Image(graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2804dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'Searcher'}}\n",
      "----\n",
      "Arguments are: data science Germany None 5 None None None\n",
      "['3803763473', '3703401972', '3888041228', '3860328669', '3808181363']\n",
      "{'Searcher': {'messages': [HumanMessage(content=\"Here are the top 5 relevant data science jobs found in Germany:\\n\\n1. **Volunteer: Microfinance Project in South Africa**\\n   - **Company:** Global Nomadic\\n   - **Location:** Munich, Bavaria, Germany\\n   - **Description:** This internship involves setting up and implementing a microfinance initiative to address poverty and unemployment. You'll collaborate with neighbourhood care points to help vulnerable and orphaned children. [Apply here](https://globalnomadic.com/project/swaziland-microfinance-pilot-project-internship/)\\n   - [Company Website](https://www.linkedin.com/company/global-nomadic)\\n\\n2. **Machine Learning Engineer**\\n   - **Company:** Celonis\\n   - **Location:** Darmstadt, Hesse, Germany\\n   - **Description:** You'll be designing and developing product features and customer solutions based on AI/ML approaches, contributing to the advancement of process mining technology. [Apply here](https://app.greenhouse.io/embed/job_app?token=5719500003)\\n   - [Company Website](https://www.linkedin.com/company/celonis)\\n\\n3. **Lead AI Engineer**\\n   - **Company:** THRYVE\\n   - **Location:** Berlin, Germany\\n   - **Description:** As a lead AI engineer, you'll oversee the design, development, and implementation of advanced AI algorithms and solutions, driving innovation within the company.\\n   - [Company Website](https://www.linkedin.com/company/thryvetalent)\\n\\n4. **Werkstudent Global Sales - Analytics & Solutions (w/m/d) I Beiersdorf**\\n   - **Company:** Beiersdorf\\n   - **Location:** Hamburg, Hamburg, Germany\\n   - **Description:** This position involves supporting the global sales organization with analyses, process standards, and system solutions, focusing on sales analytics and solutions. [Apply here](https://www.beiersdorf.de/karriere/jobs/159bdf24876869aa2dc6c7ffe9a34089?utm_source=linkedin&utm_medium=jobad&utm_campaign=1&utm_content=ad::96599__k::1__p::LI-LM1__b::1__j::9468_de_DE__ex::0__pid::auto_c16_j9468_de_DE_d20240407)\\n   - [Company Website](https://www.linkedin.com/company/beiersdorf)\\n\\n5. **Testingenieur Kabinensysteme – Luftfahrt (all gender)**\\n   - **Company:** ALTEN Germany\\n   - **Location:** Hamburg, Hamburg, Germany\\n   - **Description:** You'll be testing mechanical and electrical/electronic systems, including connectivity, ventilation systems, or power systems of various aircraft and cabin systems. [Apply here](https://www.alten-germany.de/jobs/743999960065183-testingenieur-kabinensysteme-luftfahrt-all-gender/apply)\\n   - [Company Website](https://www.linkedin.com/company/altengermany)\\n\\nFor the next part of your request regarding analyzing your CV and writing a cover letter, could you please provide your CV or key details from it?\", name='Searcher')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'Searcher'}}\n",
      "----\n",
      "{'Searcher': {'messages': [HumanMessage(content='Please provide your CV or the key details from it so that I can proceed with analyzing it and writing a cover letter for the job that best matches your profile.', name='Searcher')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'Analyzer'}}\n",
      "----\n",
      "{'Analyzer': {'messages': [HumanMessage(content=\"Based on the provided CV details, the job that best matches your profile appears to be the **Machine Learning Engineer** position at **Celonis** in Darmstadt, Hesse, Germany. Your extensive experience in NLP engineering, specifically leading the Generative AI backend team at Accenture and successfully launching NLP-powered systems, aligns well with the responsibilities of designing and developing product features based on AI/ML approaches. Additionally, your background in backend development and your proficiency in Python, PyTorch, and other relevant technologies make you a strong candidate for this role. \\n\\nNow, let's proceed with crafting a customized cover letter for this position:\\n\\n---\\n\\nTouhidul Alam  \\nMunich, Germany  \\n+49-151-56037142  \\ntapos.alam@gmail.com  \\n[Date]\\n\\nHiring Manager  \\nCelonis  \\nDarmstadt, Hesse, Germany  \\n\\nDear Hiring Manager,\\n\\nI am writing to express my enthusiasm for the Machine Learning Engineer position at Celonis, as advertised. With a deep-rooted passion for AI and ML technologies, coupled with my extensive experience in NLP engineering and backend development, I am eager to bring my expertise to Celonis and contribute to advancing process mining technology.\\n\\nDuring my tenure as an NLP Engineering Specialist at Accenture, I led the Generative AI backend team at the Liquid Studio, where I played a pivotal role in developing PoCs/demos, fine-tuning LLM for client use cases, and successfully launching a state-of-the-art NLP-powered recommendation system in production. This experience has honed my skills in not only developing AI-powered applications but also in understanding and addressing complex client requirements.\\n\\nMy academic background in Computational Linguistics from the University of Stuttgart further complements my practical experience, providing me with a solid foundation in the theoretical aspects of language processing and AI. Additionally, my hands-on experience with programming languages such as Python, and tools like PyTorch and Langchain, aligns well with the technical requirements of the Machine Learning Engineer role at Celonis.\\n\\nI am particularly drawn to Celonis due to its innovative approach to process mining and its commitment to leveraging AI/ML technologies to drive efficiency and insights. I am excited about the opportunity to contribute to designing and developing product features that harness the power of AI/ML, and I am confident that my background and skills make me a strong fit for this role.\\n\\nThank you for considering my application. I look forward to the opportunity to discuss how I can contribute to the success of Celonis as a Machine Learning Engineer. Please find my resume attached for more details on my experiences and achievements.\\n\\nSincerely,\\n\\nTouhidul Alam\\n\\n[Attachment: Resume]\\n\\n---\\n\\nThis cover letter highlights your relevant experience, aligns your skills with the job requirements, and expresses your interest in the role and the company. Remember to tailor the date and any additional personal touches or specific achievements you wish to include before sending it along with your application.\", name='Analyzer')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'FINISH'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for s in graph.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Find data science job for me in Germany maximum 5 relevant one. Then analyze my CV and write me a cover letter according to the best matching job.\")]},\n",
    "    {\"recursion_limit\": 100},\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9aa84af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find data engineering job for me maximum 10 in Germany. Then choose the most relevant one and write me a slightly modified cv for that job\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f70f589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
